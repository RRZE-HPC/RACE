\documentclass[sigplan, review]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{xspace} 


% Copyright
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

\settopmatter{printacmref=false}

% DOI
\acmDOI{}

% ISBN
\acmISBN{}

%Conference
\acmConference[SC'18]{Supercomputing Conference}{November 2018}{Dallas,TX USA}
\acmYear{}
\copyrightyear{2018}

%\acmPrice{15.00}

%\acmBadgeL[http://ctuning.org/ae/ppopp2016.html]{ae-logo}
%\acmBadgeR[http://ctuning.org/ae/ppopp2016.html]{ae-logo}

% Submission ID
%\acmSubmissionID{123-A56-BU3}

\newcommand{\RAC}{RAC\xspace}
\newcommand{\RACfull}{Recursive Algebraic Coloring\xspace}
\newcommand{\RACE}{RACE\xspace}
\newcommand{\RACEfull}{Recursive Algebraic Coloring Engine\xspace}
\newcommand{\DONE}{distance-$1$\xspace}
\newcommand{\DTWO}{distance-$2$\xspace}
\newcommand{\DK}{distance-$k$\xspace}
\newcommand{\etal}{et al.\xspace}
\newcommand{\RSB}{RSB\xspace}
\newcommand{\SpMV}{SpMV\xspace}
\newcommand{\SymmSpmv}{SymmSpMV\xspace}
\newcommand{\SpMTV}{SpMTV\xspace}
\newcommand{\GS}{GS\xspace}
\newcommand{\SYMMGS}{SymmGS\xspace}
\newcommand{\KACZ}{KACZ\xspace}
\newcommand{\SYMMKACZ}{SymmKACZ\xspace}
\newcommand{\Intel}{Intel\xspace}
\newcommand{\AMD}{AMD\xspace} 
\newcommand{\IVB}{Ivy-Bridge\xspace}
\newcommand{\BDW}{Broadwell\xspace}
\newcommand{\SKX}{Sky-Lake\xspace}
\newcommand{\NAP}{Naples\xspace}
\newcommand{\EPY}{Epyc\xspace}
\newcommand{\CRS}{CRS\xspace}
\newcommand{\CRSfull}{Compressed Row Storage\xspace}
\newcommand{\MC}{MC\xspace}
\newcommand{\MCfull}{multi-coloring\xspace}
\newcommand{\ABMC}{ABMC\xspace}
\newcommand{\ABMCfull}{algebraic block multi-coloring\xspace}
\newcommand{\NNZR}{$N_{nzr}$\xspace}
\newcommand{\NNZRSYMM}{$N_{nzr}^{symm}$\xspace}
\newcommand{\NNZRmath}{N_{nzr}\xspace}
\newcommand{\NNZRmathSYMM}{N_{nzr}^{symm}\xspace}
\newcommand{\LIKWID}{LIKWID\xspace}
\newcommand{\likwidBench}{$likwid-bench$\xspace}
\newcommand{\LLC}{LLC\xspace}
\newcommand{\LLCfull}{last level cache\xspace}
\newcommand{\ie}{i.e.,\xspace}
\newcommand{\ESSEX}{ESSEX\xspace}
\newcommand{\LCCfull}{Low Core Count\xspace}
\newcommand{\LCC}{LCC\xspace}
\newcommand{\HCCfull}{High Core Count\xspace}
\newcommand{\HCC}{HCC\xspace}
\newcommand{\MB}{MB\xspace}
\newcommand{\KB}{kB\xspace}
\newcommand{\GB}{GB\xspace}
\newcommand{\TB}{TB\xspace}
\newcommand{\SIMD}{SIMD\xspace}
\newcommand{\RCMfull}{Reverse Cuthill McKee\xspace}
\newcommand{\RCM}{RCM\xspace}
\newcommand{\CMfull}{Cuthill McKee\xspace}
\newcommand{\BFSfull}{Breadth First Search\xspace}
\newcommand{\BFS}{BFS\xspace}
\newcommand{\CPU}{CPU\xspace}
\newcommand{\pt}{pt.\xspace}
\newcommand{\STEX}{2d-7pt stencil\xspace}
\newcommand{\Inorder}{In order\xspace}
\newcommand{\inorder}{in order\xspace}
\newcommand{\levelPtr}{{\tt level\_ptr}\xspace}
\newcommand{\atleast}{at least\xspace}
\newcommand{\totalLvl}{$n_l$\xspace}
\newcommand{\totalLvlMATH}{n_l}
\newcommand{\level}{$level$\xspace}
\newcommand{\levels}{$levels$\xspace}
\newcommand{\levelGroup}{$level \text{  } group$\xspace}
\newcommand{\levelGroups}{$level \text{  } groups$\xspace}
\newcommand{\LevelGroups}{$Level \text{  } groups$\xspace}
\newcommand{\eg}{e.g.,\xspace}
\newcommand{\aka}{a.k.a.\xspace}
\newcommand{\subgraph}{sub-graph\xspace}
\newcommand{\subgraphs}{sub-graphs\xspace}
\newcommand{\levelTree}{{\tt level\_tree}\xspace}
\newcommand{\HPC}{HPC\xspace}
\newcommand{\effPar}{\emph{effective parallelism}\xspace}
\newcommand{\effRow}{\emph{effective row}\xspace}
\newcommand{\EffRow}{\emph{Effective row}\xspace}
\newcommand{\nthreads}{${n_{t}}$\xspace}
\newcommand{\nthreadsMath}{n_{t}\xspace}
\newcommand{\nrows}{${n_{r}}$\xspace}
\newcommand{\nrowsMath}{n_{r}\xspace}
\newcommand{\nrowsNospace}{${n_{r}}$}
\newcommand{\nnz}{${n_{nz}}$\xspace}
\newcommand{\nnzMath}{n_{nz}\xspace}
\newcommand{\nrowsEff}{${n_{r}^{eff}}$\xspace}
\newcommand{\nrowsEffMath}{n_{r}^{eff}\xspace}
\newcommand{\threadEff}{${n_{t}^{eff}}$\xspace}
\newcommand{\threadEffMath}{n_{t}^{eff}\xspace}
\newcommand{\upto}{up to \xspace}
\newcommand{\fracUnit}[2]{\Big[\frac{\mbox{#1}}{\mbox{#2}}\Big]}
\newcommand{\unit}[1]{\Big[\mbox{#1}\Big]}
\newcommand{\roofline}{roofline\xspace}
\newcommand{\METIS}{METIS\xspace}
\newcommand{\COLPACK}{COLPACK\xspace}
\newcommand{\SPMP}{Intel SpMP\xspace}
\newcommand{\MKL}{MKL\xspace}

\begin{document}
\title[RACE]{Recursive Algebraic Coloring Engine}
%\titlenote{Produces the permission block, and
%  copyright information}
\subtitle{Poster Summary}
%\subtitlenote{The full version of the author's guide is available as
%  \texttt{acmart.pdf} document}

\author{Christie Louis Alappat}
%\orcid{1234-5678-9012-3456}
\affiliation{%
	\institution{Friedrich-Alexander-Universit{\"a}t Erlangen-N{\"u}rnberg}
	\city{Erlangen}
	\country{Germany}}
\email{christie.alappat@fau.de}

\author{Georg Hager}
\affiliation{%
	\institution{Friedrich-Alexander-Universit{\"a}t Erlangen-N{\"u}rnberg}
	\city{Erlangen}
	\country{Germany}
}
\email{georg.hager@fau.de}

\author{Gerhard Wellein}
\affiliation{%
	\institution{Friedrich-Alexander-Universit{\"a}t Erlangen-N{\"u}rnberg}
	\city{Erlangen}
	\country{Germany}
}
\email{gerhard.wellein@fau.de}

\author{Olaf Schenk}
\affiliation{%
	\institution{Institute of Computational Science}
	\city{Lugano}
	\country{Switzerland}
}
\email{olaf.schenk@usi.ch}

% The default list of authors is too long for headers.
\renewcommand{\shortauthors}{C. Alappat et al.}



\begin{abstract}
Many iterative numerical methods for sparse systems and important building blocks of sparse linear algebra feature strong data dependencies. They may be loop-carried dependencies as they occur in many iterative solvers or preconditioners (e.g., Gauss-Seidel, Kaczmarz) or write conflicts as in the parallelization of building blocks such as symmetric sparse matrix vector or sparse matrix transpose vector multiplication. Scalable, hardware-efficient parallelization of such kernels is known to be a challenge. Most of the typical solutions suffer from low performance on modern hardware, are highly matrix specific, or require tailored matrix storage formats.

In this poster we show a novel method called Recursive Algebraic Coloring (RAC), which achieves high hardware efficiency on modern multi-core architectures and works with simple data formats like compressed row storage (CRS). RAC uses a recursive level-based method that aims at finding optimal permutations while preserving data locality. It is implemented and consolidated into a user-friendly library called Recursive Algebraic Coloring Engine (RACE). A thorough performance analysis shows that RACE outperforms traditional Multicoloring methods and Intel MKL implementations with a factor of 2--2.5$\times$. We are on par with Algebraic Block Multicoloring (ABMC) for small matrices, while for large matrices we gain almost a factor of 1.5--2$\times$.
\end{abstract}



\keywords{Shared memory parallel, Distance-k dependency, Graph algorithm, Sparse matrices, Sparse linear algebra, Performance}

%\begin{teaserfigure}
%  \includegraphics[width=\textwidth]{sampleteaser}
%  \caption{This is a teaser}
%  \label{fig:teaser}
%\end{teaserfigure}


\maketitle

\input{RACE_body}

\bibliographystyle{ACM-Reference-Format}
\bibliography{RACE_references}

\end{document}
