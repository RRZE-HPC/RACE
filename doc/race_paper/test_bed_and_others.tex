\subsection{Test bed}
{\GW ToDo: EPYC raus;}
The tests are conducted on three different multi-core architectures. Two of them being Intel's \IVB and modern \SKX architecture, the choice of these architectures enable study of the method on two extreme generation of Intel's processor currently being used on \HPC systems. As a third choice we select AMD's recent \EPY architecture, which is competitive to Intel \SKX architecture. This choice enables us to study the effect of our method on chips based on completely different microarchitecture, enabling us to demonstrate the applicability of our method on wide range of architectures. All the tests are conducted on a single socket of these architectures. 

\begin{itemize}
	\item \Intel \IVB architecture belongs to class of classic Intel's cache-based architecture, which has three inclusive cache  hierarchies. All the cache are scalable and the \LLC (L3) being shared among all the cores on one socket. The processor is capable of delivering one full four wide \SIMD add, multiply and load in one cycle. 
	\item \Intel \SKX architecture belongs to recent generation of Intel family. Contrary to it's predecessors (like \IVB), L3 cache is now changed to a non-inclusive victim cache shared by all the cores on a socket. The architecture comes with support for eight wide \SIMD operations (AVX-512). The processor is capable of doing two AVX-512 add, multiply and load operations per cycle.
	\item {\GW \AMD \EPY is based on AMD's Zen microarchitecture. The basic building block of the architecture consists of Core Complex (CCX) consisting of three cores (can extend upto four on high end models) each having it's own private L1 and L2 cache. The L3 cache is shared between a core complex and is non-inclusive victim cache. A single socket of \EPY consists of eight such CCX.}
	
\end{itemize}
The details of architectures along with the measured bandwidths are given in \cref{tab:test_bed}. {\GW The bandwidths are measured using \likwidBench suite.}

\begin{table}[tbhp]
\footnotesize
\caption{Test bed}\label{tab:test_bed}
\begin{center}
%	\setlength{\tabcolsep}{3em}
	\begin{tabular}{|l| c  c c |}
		\toprule
		{Model name} & {Xeon\textsuperscript{\textregistered} E5-2660} & {Xeon\textsuperscript{\textregistered} Gold 6148} & { Epyc 7451 } \\
		\midrule
		{Microarchitecture} & {Ivy Bridge} & {Skylake} & {Zen} \\
		\midrule
		{Clock} & {2.2 GHz} & {2.4 GHz} & {2.3 GHz}\\
		{Physical Cores per socket} & {10} & {20} & {24}\\
		{L1d Cache} & {10 $\times$ 32 \KB} & {20 $\times$ 32 \KB} & {24 $\times$  32 \KB}\\
		{L2 Cache} & {10 $\times$ 256 \KB} & {20 $\times$ 1 \MB} & {24 $\times$ 512 \MB }\\
		{L3 Cache} & {25 \MB} & {27.5 \MB} & {8 $\times$ 8 \MB}\\
		{L3 type} & {inclusive} & {non-inclusive} & {non-inclusive}\\
		{Main Memory} & {32 GB} & {45 GB} & {4 $\times$ 16 GB}\\
		{Bandwidth per socket - load only} & {47 GB/s} & {115 GB/s} & {130 GB/s }\\ %TODO
		{Bandwidth per socket - copy} & {40 GB/s} & {104 GB/s} & {114 GB/s }\\
		\bottomrule
	\end{tabular}
\end{center}
\end{table} 

Furthermore all the measurements were done with  \CPU clock speeds fixed at frequencies indicated in \cref{tab:test_bed}.


\subsection{External Tools and Software}
Following external libraries are used in this paper. The application of these libraries will be stated at the point it is needed.
\begin{itemize}
	%TODO
	\item \LIKWID \cite{LIKWID} \text{\tt{likwid-perfctr}} is used for measuring hardware performance counters and \text{\tt{likwid-bench}}  for measuring bandwidth.
	\item \COLPACK \cite{COLPACK} is used for pre-processing matrix by \MCfull.
	\item \SPMP \cite{SpMP} is used to perform \RCMfull (\RCM).
	\item \METIS\cite{METIS} is used for graph partitioning.
	\item All the code used was compiled with Intel compiler version 17 and the following compiler flags were set {\tt -fno-alias -xHost -O3} for Ivy-Bridge system and {\tt -fno-alias -xCORE-AVX512 -O3} for Skylake system {\GW Christie please check and specify exact Compiler version}
	\item \MKL \cite{MKL} is used for performing some reference sparse matrix computations.
\end{itemize}

\subsection{Benchmark Matrices}
All the test matrices are taken from SuiteSparse Matrix Collection (former University of Florida Sparse Matrix Collection) \cite{UOF} and quantum mechanics field (see \ESSEX project \cite{ESSEX} for more details). The selection of the matrices from SuiteSparse Matrix Collection is  mainly done by combining the test matrices from two papers \cite{RSB,park_ls}. This enables easy comparison of results. Matrices from \ESSEX project are some of the matrices that are of interest in the iterative FEAST eigen value solver that internally uses Kaczmarz solver.  Only matrices having undirected graphs are considered due to scope of the paper as mentioned in \cref{Sec:contribution}. Matrices along with some of their parameters are given in \cref{table:bench_matrices}.  Matrices that have been marked with an * symbol indicate they are corner cases and will be discussed in detail.

\begin{table}[ht]
	\footnotesize
	\caption{Benchmark matrices}\label{tab:test_mtx}
	\label{table:bench_matrices}
	\begin{center}
		\input{pics/matrices/table.tex}
	\end{center}

\end{table}

\subsection{Kernels} \label{subsec:test_kernels}
We evaluate our methods by parallelizing two simple but important kernels showing distance-2 dependencies. In the context of parallelization of symmetric sparse matrix vector (\SymmSpmv) the distance-2 coloring procedure prevents from concurrent update of the same vector entries by different threads resulting in the same result as the serial code ("exact kernel").  {\GW To be done As an example for an iterative solver with distance2 dependency we have chosen the \KACZ ...}

Both algorithms are closely related by structure and computational intensity to the widely used \SpMV kernel applicable to general matrices. Thus, we start with presenting the \SpMV kernel and its known computational intensity. We extend this discussion towards the \SymmSpmv and \KACZ and show how to derive upper realistic performance bounds. We chose the widely used \CRS matrix storage format for the serial implementation of the kernel and assume square matrices.

\subsubsection{\SpMV}
The \SpMV has no loop carried dependencies and parallelization of outer ($row$) loop using, e.g. OpenMP, is straightforward. 
\begin{algorithm}[H]
	\caption{SpMV Find $b$ : $b=A x$} 
	\label{alg:SpMV}
	\begin{algorithmic}[1]
	        \STATE{$double:: A[nnz], b[nrows], x[nrows]$}
	        \STATE{$integer:: col[nnz], rowPtr[nrows+1]$}
		\FOR{$row=1:nrows$}
		\FOR{$idx=rowPtr[row]:rowPtr[row+1]$}
		\STATE{$b[row] += A[idx]*x[col[idx]]$} 
		\ENDFOR
		\ENDFOR
	\end{algorithmic}
\end{algorithm}
Following the discussion in~\cite{Moritz_sell} the computational intensity of the above kernel $I_\mathrm{\SpMV}$  is as follows:
\begin{equation}
\label{eq:SpMV_intensity}
I_\mathrm{\SpMV} = \frac{2}{8+4+8*\alpha+\frac{20}{\NNZRmath}} \frac{Flop}{Byte} \\
\end{equation}
Here we assume that matrix data  ($A[], col[]$), left hand side vector ($b[]$) and row pointer information ($rowPtr[]$) are loaded once from main memory as these data structures are consecutively accessed. All quantities are calculated for the average costs of computing one non-zero element of the matrix. Thus, contributions which are independent of the inner (short) loop are rescaled by $\NNZRmath$ which is the average number of non-zeros per row (i.e. the average length of the inner loop).

The $8*\alpha$ term represents contribution of accessing the right hand side (RHS) vector ($x[]$) irregularly. The value of $\alpha$ depends on the matrix structure (access pattern) as well as on the RHS vector data set size compared to the largest cache size. The smallest value of $\alpha=\frac{1}{\NNZRmath}$ is attained if the RHS vector is only loaded once from main memory to the cache and all subsequent accesses in the same \SpMV are cache hits. This limit is typically realized for matrices with low bandwidth (high access locality) or if the cache is large enough to hold the full RHS data during one \SpMV. The factor $\alpha$ can be determined by measuring the data traffic when executing the \SpMV; please see~\cite{Moritz_sell} for more details~\footnote{In~\cite{Moritz_sell} the traffic for the row pointer was not accounted, i.e. the denominator increases by $\frac{4}{\NNZRmath} Byte$.}.

\begin{comment}
\subsubsection{\SpMTV}
Sparse Matrix Transpose Vector (\SpMTV) is a kernel having \DTWO dependency.
\begin{algorithm}[H]
	\caption{SpMTV Find $b$ : $b=A'x$} 
	\label{alg:SpMTV}
	\begin{algorithmic}[1]
		\FOR{$row=1:nrows$}
		\FOR{$idx=rowPtr[row]:rowPtr[row+1]$}
		\STATE{$b[col[idx]] += A[idx]*x[row]$} 
		\ENDFOR
		\ENDFOR
	\end{algorithmic}
\end{algorithm}
In comparison to SpMV operation, the kernel requires an extra scatter operation, which causes dependency. The arithmetic intensity of the kernel $I_\mathrm{\SpMTV}$ is given as:
\begin{equation}
\label{eq:SpMTV_intensity}
I_\mathrm{\SpMTV} = \frac{2}{8+4+16*\alpha+\frac{8}{\NNZRmath}} \\
\end{equation}
In ideal case data traffic for this kernel should remain close to that of SpMV, if \NNZR are sufficiently high, and $\alpha$ factor is small enough.
\end{comment}

\subsubsection{\SymmSpmv}
Symmetric Sparse Matrix Vector (\SymmSpmv) exploits the symmetry in the underlying matrix to reduce storage size for matrix data and reduce overall memory traffic by  operating on the upper (or lower) half of the matrix. Thus for every non-zero matrix entry we need to update two entries in the RHS vector as shown in~\cref{alg:SymmSpMV}.
\begin{algorithm}[H]
	\caption{SymmSpMV Find $b$ : $b=Ax$, where $A$ is an upper triangular matrix} 
	\label{alg:SymmSpMV}
	\begin{algorithmic}[1]
		\FOR{$row=1:nrows$}
		\STATE{$diag\_idx=rowPtr[row]$}
		\STATE{$b[row] += A[diag\_idx]*x[row]$}
		\FOR{$idx=rowPtr[row]+1:rowPtr[row+1]$}
		\STATE{$b[row] += A[idx]*x[col[idx]]$}
		\STATE{$b[col[idx]] += A[idx]*x[row]$} 
		\ENDFOR
		\ENDFOR
	\end{algorithmic}
\end{algorithm}
In line with the discussion above the computational intensity of \SymmSpmv can be calculated as:
\begin{equation}
\label{eq:SymmSpMV_intensity}
I_\mathrm{\SymmSpmv} = \frac{4}{8+4+24*\alpha+\frac{4}{\NNZRmathSYMM}} \frac{Flop}{Byte}\\
\end{equation}
For a given non-zero matrix element ($8 Byte + 4 Byte$) of the triangular matrix twice the amount of Flops ($4 Flops$)  are performed. In addition we have indirect access to the LHS vector (read and write) which increases the $alpha$ contribution by $3x$. The only term left scaling with \NNZRSYMM (number of non-zeros per row in upper triangular part of the matrix) is the consecutively accessed row pointer. Please note, the $alpha$ value for \SpMV and \SymmSpmv may be different (even for the same matrix and the same compute device) as in the latter case the two vectors are accessed irregularly and compete for the same amount of cache. 

\begin{comment}
\subsubsection{\GS and \SYMMGS}
Gauss-Seidel (\GS) is a solver having distance-1 dependency. Contrary to the above kernels \GS is in-exact meaning it is an iterative method. \Cref{alg:GS} shows the Gauss-Seidel algorithm where its assumed that the diagonal entries of the matrix are stored as first entry in their corresponding rows.
\begin{algorithm}[H]
	\caption{GS Solve for $x$ : $Ax=b$} 
	\label{alg:GS}
	\begin{algorithmic}[1]
		\FOR{$row=1:nrows$}
		\STATE{$x[row]+=b[row]$}
		\FOR{$idx=rowPtr[row]+1:rowPtr[row+1]$}
		\STATE{$x[row] -= A[idx]*x[col[idx]]$} 
		\ENDFOR
		\STATE{$diag=A[rowPtr[row]]$}
		\STATE{$x[row]/=diag$}
		\ENDFOR
	\end{algorithmic}
\end{algorithm}
Regarding the in-core execution the kernel has same properties as of \SpMV, but requires an additional divide operation per row of the matrix. If the locality ($\alpha$ factor) is not disturbed due to pre-processing the kernel requires same data traffic as of \SpMV. The arithmetic intensity of \GS is the same as that of \SpMV, if we neglect the divide operation that occurs once per every row.
\begin{equation}
\label{eq:GS_intensity}
I_\mathrm{GS} = I_\mathrm{SPMV}
\end{equation}

In general for most of the algorithms one is interested in symmetric operator therefore commonly one would encounter symmetric variant of Gauss-Seidel, so called symmetric Gauss-Seidel (\SYMMGS). The algorithm remains same except that instead of just doing forward sweep shown in \cref{alg:GS} one would follow it with a backward sweep \ie {\tt row=nrows:-1:1}. The intensity of \SYMMGS remains same as of \GS, as we do two times more flops and bring in proportional data.
\end{comment}

\subsubsection{KACZ and \SYMMKACZ}
Kaczmarz (\KACZ) is an iterative solver based on row-projection based methods. The solver has a distance-2 dependency.
\begin{algorithm}[H]
	\caption{KACZ Solve for $x$ : $Ax=b$} 
	\label{alg:KACZ}
	\begin{algorithmic}[1]
		\FOR{$row=1:nrows$}
		\STATE{$row\_norm=0$}
		\STATE{$scale=b[row]$}
		\FOR{$idx=rowPtr[row]:rowPtr[row+1]$}
		\STATE{$scale -= A[idx]*x[col[idx]]$}
		\STATE{$rownorm += A[idx]*A[idx]$} 
		\ENDFOR
		\STATE{$scale=scale/rownorm$}
		\FOR{$idx=rowPtr[row]:rowPtr[row+1]$}
		\STATE{$x[col[idx]] += scale*A[idx]$} 
		\ENDFOR
		\ENDFOR
	\end{algorithmic}
\end{algorithm}

In-core has a mixed behavior of both SpMV and SpMTV similar to SymmSpMV. The solver also requires a divide per  row of the matrix. In ideal case the data traffic from memory should remain same as that of SpMTV. But the solver requires thrice the flops compared to SpMTV per non-zero. For brevity of the results we ignore the flops used in $rownorm$ computations since, one could also row normalize the sparse matrix before performing the KACZ operation. This leads to an almost two fold higher Arithmetic Intensity compared to SpMTV.
\begin{equation}
\label{eq:KACZ_intensity}
I_\mathrm{KACZ} =  \frac{4}{8+4+16*\alpha+\frac{8}{nnzr}} \\%= 2*I_\mathrm{SpMTV}\\
\end{equation}

In general for most of the algorithms one is interested in symmetric operator therefore commonly one would encounter symmetric variant of \KACZ, so called symmetric Kaczmarz (\SYMMKACZ). The algorithm remains same except that instead of just doing forward sweep shown in \cref{alg:KACZ} one would follow it with a backward sweep \ie {\tt row=nrows:-1:1}. The intensity of \SYMMKACZ remains same as of \KACZ, as we do two times more flops and bring in proportional data.
%Symmetric variant of \KACZ is denoted by \SYMMKACZ, and similar to \SYMMGS this requires forward sweep followed by a backward sweep. 